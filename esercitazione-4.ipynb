{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Esercitazione 4 - Classificatori: KNN e Decision Trees**\n\nIn questa esercitazione applicheremo quanto appreso sui classificatori. Nello specifico utilizzeremo:\n\n* **K-Nearest Neighbors (KNN):** Un algoritmo di classificazione basato sulla similarità che assegna una classe a un'osservazione in base alle classi dei suoi \"K\" vicini più prossimi.\n\n* **Decision Trees:** Un modello di classificazione che utilizza una struttura ad albero per prendere decisioni basate su regole derivate dalle caratteristiche dei dati.","metadata":{}},{"cell_type":"markdown","source":"### **Dataset Breast Cancer**\n\nIl dataset di riferimento sarà `breast_cancer`, un noto dataset di classificazione che contiene informazioni su tumori al seno. Le osservazioni includono diverse caratteristiche misurate sui tumori, come dimensioni, forma e altre metriche, con l'obiettivo di classificare i tumori in due categorie: **benigni** e **maligni**.\n\nPer questa esercitazione, utilizzeremo l'intero dataset, mantenendo le classi originali. Il dataset è composto da 569 campioni e 30 caratteristiche, e utilizzeremo questo set per costruire i modelli di classificazione.\n\nIl codice seguente esegue l'importazione delle librerie necessarie, il caricamento del dataset `breast_cancer` e la preparazione dei dati. In particolare, gestiremo i dati e le etichette in modo da facilitare l'uso dei classificatori K-Nearest Neighbors (KNN) e Decision Trees.\n\nDal caricamente del dataset estrarremo anche i nomi delle feature e della variabile target perchè ci servirà più avanti.","metadata":{}},{"cell_type":"code","source":"# Importazione delle librerie necessarie\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T12:26:53.415592Z","iopub.execute_input":"2025-04-24T12:26:53.415814Z","iopub.status.idle":"2025-04-24T12:26:57.737708Z","shell.execute_reply.started":"2025-04-24T12:26:53.415794Z","shell.execute_reply":"2025-04-24T12:26:57.736867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Caricamento del dataset Iris\ndataset = load_breast_cancer()\nX = dataset.data\ny = dataset.target\n\n# Estraggo nomi delle feature e dei target\nfeature_names = dataset.feature_names\ntarget_names = dataset.target_names\nprint(y.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T12:28:16.999238Z","iopub.execute_input":"2025-04-24T12:28:16.999543Z","iopub.status.idle":"2025-04-24T12:28:17.015846Z","shell.execute_reply.started":"2025-04-24T12:28:16.999517Z","shell.execute_reply":"2025-04-24T12:28:17.015022Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Divisione e standardizzazione del dataset** \n\nDividiamo il dataset in `train set`, `validation set` e `test set` utilizzando le proporzioni già impostate. Successivamente applichiamo la standardizzazione utilizzando `StandardScaler`.","metadata":{}},{"cell_type":"code","source":"# Usare le seguenti proporzioni per il train, validation e test\ntrain_fraction = 0.6  \nvalidation_fraction = 0.2  \ntest_fraction = 0.2\n\n# svolgimento...\nnum_train = int(train_fraction * X.shape[0])\nnum_validation = int(validation_fraction * X.shape[0])\n\nX_train = X[:num_train]\ny_train = y[:num_train]\n\nX_validation = X[num_train:num_train+num_validation]\ny_validation = y[num_train:num_train+num_validation]\n\nX_test = X[num_train+num_validation:]\ny_test = y[num_train+num_validation:]\n\nscaler = StandardScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_validation = scaler.transform(X_validation)\nX_test = scaler.transform(X_test)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:14:12.610029Z","iopub.execute_input":"2025-04-24T14:14:12.610795Z","iopub.status.idle":"2025-04-24T14:14:12.618122Z","shell.execute_reply.started":"2025-04-24T14:14:12.610766Z","shell.execute_reply":"2025-04-24T14:14:12.617456Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Esercizio 1: Implementare K-NN**\n\nPer implementare il classificatore K-Nearest Neighbors utilizzeremo la classe `sklearn.neighbors.KNeighborsClassifier` presente in `scikit-learn`. La documentazione è disponibile [a questo link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html).\n\nDi seguito vediamo i parametri chiave che bisogna specificare al momento della creazione dell'istanza:\n\n* **`n_neighbors`**: Numero di vicini da considerare. Valori più elevati implicano una maggiore generalizzazione.\n* **`weights`**: Specifica come pesare i vicini; può essere `uniform` (tutti i vicini hanno lo stesso peso) o `distance` (i vicini più prossimi hanno un peso maggiore).\n* **`metric`**: Tipo di distanza da utilizzare per calcolare la distanza tra i punti (ad esempio, `euclidean`, `manhattan`, ecc.).\n\n### Esempio di sintassi per istanziare, addestrare e predire\n\n```python\n# Importo KNeighborsClassifier da scikit-learn\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# 1. Instanzio il modello KNN\n# Durante la creazione dell'istanza imposto i parametri che desidero\nmodel = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean')\n\n# 2. Train del modello utilizzando il metodo .fit()\nmodel.fit(X_train, y_train)\n\n# 3. Calcolo delle predizioni utilizzando il metodo .predict()\npredictions = model.predict(X_test)\n\n```","metadata":{}},{"cell_type":"markdown","source":"### **Guida per la risoluzione del K-Nearest Neighbors (KNN)**\n\nDi seguito sono spiegati i passaggi principali per la risoluzione dell'esercizio utilizzando il classificatore K-Nearest Neighbors.\n\n1. **Creazione del modello:** Creare un'istanza della classe `KNeighborsClassifier`, specificando i parametri presentati poco sopra. In particolare vogliamo i seguenti parametri:\n\n    - `n_neighbors` = 5\n\n    - `weights` = `'uniform'` (o `'distance'` se vuoi dare un peso maggiore ai vicini più prossimi)\n\n    - `metric` = `'euclidean'` (puoi cambiare con `'manhattan'` se preferisci un'altra metrica di distanza)\n\n2. **Addestramento del modello:** Addestriamo il modello utilizzando il metodo `.fit()`. Il modello deve essere addestrato sui dati di training. Assicurati che i dati siano adeguatamente preprocessati e, se necessario, normalizzati o standardizzati.\n\n3. **Calcolo delle predizioni:** Calcoliamo le predizioni sul validation e sul test set utilizzando il metodo `.predict()` del modello.\n\n4. **Valutazione delle prestazioni del modello:** Calcoliamo l'accuracy del modello. Possono essere utilizzate anche altre metriche, come la precisione, il richiamo e il punteggio F1, per ottenere una valutazione più completa. Dobbiamo valutare il modello sia sul validation set che sul test set e infine stampare il valore di accuracy su entrambi i set.\n\n5. **Calcolare la matrice di confusione:** Calcolare la matrice di confusione.","metadata":{}},{"cell_type":"code","source":"# Step 1: Creazione del modello KNN\n\n# svolgimento...\n\nknn = KNeighborsClassifier(\n    n_neighbors=5,\n    weights='uniform',\n    metric='euclidean'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:14:21.322291Z","iopub.execute_input":"2025-04-24T14:14:21.322991Z","iopub.status.idle":"2025-04-24T14:14:21.327119Z","shell.execute_reply.started":"2025-04-24T14:14:21.322960Z","shell.execute_reply":"2025-04-24T14:14:21.326236Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2: Addestramento del modello KNN\n\n# svolgimento...\nknn.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:14:25.299441Z","iopub.execute_input":"2025-04-24T14:14:25.299828Z","iopub.status.idle":"2025-04-24T14:14:25.366165Z","shell.execute_reply.started":"2025-04-24T14:14:25.299800Z","shell.execute_reply":"2025-04-24T14:14:25.365358Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3: Calcolo delle predizioni\n\n# svolgimento...\n\ny_pred_val = knn.predict(X_validation)\ny_pred_test = knn.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:14:48.493520Z","iopub.execute_input":"2025-04-24T14:14:48.494211Z","iopub.status.idle":"2025-04-24T14:14:48.598284Z","shell.execute_reply.started":"2025-04-24T14:14:48.494186Z","shell.execute_reply":"2025-04-24T14:14:48.597423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 4: Valutazione del modello KNN\n\n# svolgimento...\ncorrect_valid = np.sum(y_validation == y_pred_val)\ntotal_valid = len(y_validation)\nacc_valid = correct_valid / total_valid if total_valid > 0 else 0\n\ncorrect_test = np.sum(y_test == y_pred_test)\ntotal_test = len (y_test)\nacc_test = correct_test / total_test if total_test > 0 else 0\n\n\nprint(f\"Validation accuracy: {acc_valid:.4f}\")\nprint(f\"Test accuracy: {acc_test:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:18:51.218007Z","iopub.execute_input":"2025-04-24T14:18:51.218330Z","iopub.status.idle":"2025-04-24T14:18:51.224424Z","shell.execute_reply.started":"2025-04-24T14:18:51.218307Z","shell.execute_reply":"2025-04-24T14:18:51.223746Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Funzione alternativa per il calcolo dell' accuracy\n\nFinora abbiamo calcolato manualmente il valore dell' accuracy. Ovvero abbiamo confrontato il vettore delle predizioni con il vettore dei target e successivamente contato quanti campioni combaciano, in modo da avere il numero di predizioni effettuate correttamente. Possiamo effettuare questo calcolo anche utilizzando una funzione di `sklearn`.\n\nLa funzione `accuracy_score` infatti ci calcola in automatico il valore dell' accuracy. La sintassi per utilizarla è la seguente\n\n```python\n# Importo accuracy_score da scikit-learn\nfrom sklearn.metrics import accuracy_score\n\naccuracy = accuracy_score(y_true, y_pred)\n\n```","metadata":{}},{"cell_type":"code","source":"# Step 4.1: Calcolare l' accuracy con accuracy_score\n\n# svolgimento...\n\naccuracy = accuracy_score(y_test, y_pred_test)\nprint(\"Accuracy sul test set:\", accuracy)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:19:08.316344Z","iopub.execute_input":"2025-04-24T14:19:08.316643Z","iopub.status.idle":"2025-04-24T14:19:08.322984Z","shell.execute_reply.started":"2025-04-24T14:19:08.316620Z","shell.execute_reply":"2025-04-24T14:19:08.322173Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 5: Calcolare la matrice di confusione\n\n# svolgimento...\n\n\nconf_matrix = confusion_matrix(y_test, y_pred_test)\nprint(\"Matrice di confusione (test set):\\n\", conf_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:19:11.633398Z","iopub.execute_input":"2025-04-24T14:19:11.633722Z","iopub.status.idle":"2025-04-24T14:19:11.644806Z","shell.execute_reply.started":"2025-04-24T14:19:11.633676Z","shell.execute_reply":"2025-04-24T14:19:11.643811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_decision_boundary(knn_model, X_train, y_train):\n\n    h = 0.1  \n    x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n    y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n    \n    Z = knn_model.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n\n    unique_classes = np.unique(y_train)\n    \n    plt.figure(figsize=(10, 8))\n    plt.contourf(xx, yy, Z, alpha=0.5, cmap=plt.cm.RdYlBu)  \n    \n    scatter = plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolors='k', marker='o', \n                          label='Training set', cmap=plt.cm.RdYlBu, s=20)  \n\n    plt.title(f'Confini Decisionali di K-Nearest Neighbors')\n    plt.legend(scatter.legend_elements()[0], unique_classes, title='Classi')\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:19:16.479160Z","iopub.execute_input":"2025-04-24T14:19:16.479899Z","iopub.status.idle":"2025-04-24T14:19:16.487598Z","shell.execute_reply.started":"2025-04-24T14:19:16.479871Z","shell.execute_reply":"2025-04-24T14:19:16.486757Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Visualizzazione K-NN\n\nPer visualizzare il margine di classificazione del nostro K-NN dobbiamo utilizzare soltanto 2 features. Poichè nel dataset ne sono presenti 30 abbiamo due soluzioni:\n\n1. **Utilizzare le prime due features del dataset:** soluzione più rapida ma che non ci garantisce un risultato ottimale, in quanto l' ordine delle features non ha alcuna rilevanza circa la loro importanza. **ATTENZIONE:** poichè stiamo utilizzando solo 2 features, dobbiamo riaddestrare il K-NN sul dataset ridotto.\n\n2. **Applicare PCA con 2 componenti:** applichiamo la PCA con due componenti che utilizziamo successivamente per trasformare i nostri dati.\n\nDi seguito applicheremo entrambe le soluzioni e alla fine confronteremo i risultati.","metadata":{}},{"cell_type":"code","source":"# Visualizzazione con due feature\n\n# Riduciamo il dataset prendendo soltanto le prime 2 features (colonne)\n\n# svolgimento...\n\nX_reduced = X[:, :2]\n\n\n# Standardizziamo il dataset ridotto\n\n# svolgimento...\nscaler = StandardScaler()\nX_reduced_scaled = scaler.fit_transform(X_reduced)\n\n\n# Creiamo e addestriamo il K-NN sul dataset ridotto e scalato\n\n# svolgimento...\nX_train_red, X_test_red, y_train_red, y_test_red = train_test_split(X_reduced_scaled, y, test_size=0.3, random_state=42)\n\nknn_red = KNeighborsClassifier(n_neighbors=5)\nknn_red.fit(X_train_red, y_train_red)\n\n\n\n# Utilizziamo la funzione plot_decision_boundary per visualizzare il confine decisionale\n\n# svolgimento...\nplot_decision_boundary(knn_red, X_train_red, y_train_red)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:19:20.211683Z","iopub.execute_input":"2025-04-24T14:19:20.212067Z","iopub.status.idle":"2025-04-24T14:19:21.058291Z","shell.execute_reply.started":"2025-04-24T14:19:20.212035Z","shell.execute_reply":"2025-04-24T14:19:21.057328Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualizzazione con PCA\nfrom sklearn.decomposition import PCA\n\n# Applichiamo PCA per ridurre il dataset a 2 dimensioni. ATTENZIONE: per applicare PCA dobbiamo prima standardizzare.\n\n# svolgimento...\n\nscaler_pca = StandardScaler()\nX_scaled = scaler_pca.fit_transform(X)\n\n\n# Riduzione delle dimensioni con PCA\n\n# svolgimento...\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\nX_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n\n\n\n# Classificatore KNN su dati PCA\n\n# svolgimento...\nknn_pca = KNeighborsClassifier(n_neighbors=5)\nknn_pca.fit(X_train_pca, y_train_pca)\n\n\n# Plot\n\n# svolgimento...\n           \nplot_decision_boundary(knn_pca, X_train_pca, y_train_pca)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:19:36.942048Z","iopub.execute_input":"2025-04-24T14:19:36.942879Z","iopub.status.idle":"2025-04-24T14:19:39.675622Z","shell.execute_reply.started":"2025-04-24T14:19:36.942851Z","shell.execute_reply":"2025-04-24T14:19:39.674762Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Esercizio 2: valutare le prestazioni di K-NN al variare di k e metrica**\n\nValutiamo come variano le prestazioni del classificatore al variare di:\n\n* **k:** usiamo diversi valori di k.\n\n* **metrica**: usiamo diverse distanze, non solo quella euclidea.\n\n\n### **Guida:**\n\n1. **Testiamo il classificatore al variare del parametro:** che sia il k o la distanza, dobbiamo istanziare, allenare e valutare il classificatore per ogni valore che ci interessa. Alla fine di ogni test che effettuiamo, saliamo il valore di accuracy ottenuto in una lista.\n\n2. **Valutazione grafica:** utilizziamo la funzione di plot per valutare quale valore del parametro di interesse ci fa ottenere la performance migliore.\n\n","metadata":{}},{"cell_type":"code","source":"# Funzione per la valutazione grafica\n\ndef plot_accuracy_k(k_values, train_scores, test_scores):\n    plt.figure(figsize=(12, 6))\n    \n    plt.plot(k_values, train_scores, 'o-', label='Accuratezza Training')\n    plt.plot(k_values, test_scores, 'o-', label='Accuratezza Testing')\n    \n    plt.xlabel('Numero di k')\n    plt.ylabel('Accuratezza')\n    plt.title('KNN: Accuratezza vs. Valore di k')\n    plt.legend()\n    plt.grid(True)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:50:40.815388Z","iopub.execute_input":"2025-04-24T14:50:40.815686Z","iopub.status.idle":"2025-04-24T14:50:40.821420Z","shell.execute_reply.started":"2025-04-24T14:50:40.815668Z","shell.execute_reply":"2025-04-24T14:50:40.820644Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Valutiamo le performance al variare di k\n\nk_values = range(1, 15) \ntrain_scores = []\ntest_scores = []\n\n# Istanziamo, alleniamo e valutiamo un K-NN per ogni valore di k \n\n# svolgimento...\n# Intervallo di valori di k da testare\nk_values = range(1, 15)\ntrain_scores = []\ntest_scores = []\n\n# Per ogni valore di k, alleniamo un KNN e salviamo le performance\nfor k in k_values:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    \n    # Accuracy sul training set\n    train_pred = knn.predict(X_train)\n    train_acc = accuracy_score(y_train, train_pred)\n    train_scores.append(train_acc)\n    \n    # Accuracy sul test set\n    test_pred = knn.predict(X_test)\n    test_acc = accuracy_score(y_test, test_pred)\n    test_scores.append(test_acc)\n\n\n# Visualizziamo le performance al variare di k\n# N.B. la funzione plot_accuracy_k ha bisogno dei parametri k_values, train_scores, test_scores.\n\n# svolgimento...\n\ndef plot_accuracy_k(k_values, train_scores, test_scores):\n    plt.figure(figsize=(12, 6))\n    plt.plot(k_values, train_scores, 'o-', label='Accuratezza Training')\n    plt.plot(k_values, test_scores, 'o-', label='Accuratezza Testing')\n    plt.xlabel('Numero di k')\n    plt.ylabel('Accuratezza')\n    plt.title('KNN: Accuratezza vs. Valore di k')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\nplot_accuracy_k(k_values, train_scores, test_scores)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:50:43.017387Z","iopub.execute_input":"2025-04-24T14:50:43.017742Z","iopub.status.idle":"2025-04-24T14:50:43.646547Z","shell.execute_reply.started":"2025-04-24T14:50:43.017716Z","shell.execute_reply":"2025-04-24T14:50:43.644926Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Funzione per plottare l' accuracy al variare delle metriche\n\ndef plot_accuracy_metric(metrics, train_scores, test_scores):\n    bar_width = 0.35\n    x = np.arange(len(metrics))  \n\n    plt.figure(figsize=(12, 6))\n\n    color_train = plt.cm.RdYlBu(0.9)  \n    color_test = plt.cm.RdYlBu(0.4)   \n\n    bars_train = plt.bar(x - bar_width/2, train_scores.values(), width=bar_width, label='Training', color=color_train)\n    bars_test = plt.bar(x + bar_width/2, test_scores.values(), width=bar_width, label='Testing', color=color_test)\n\n    plt.xticks(ticks=x, labels=metrics)  \n    plt.xlabel('Metriche')\n    plt.ylabel('Accuratezza')\n    plt.title('KNN: Accuratezza vs. Metriche')\n    plt.legend(loc='lower right')\n    plt.grid(axis='y')\n    \n    for bar in bars_train:\n        yval = bar.get_height()\n        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n\n    for bar in bars_test:\n        yval = bar.get_height()\n        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:51:25.207680Z","iopub.execute_input":"2025-04-24T14:51:25.208016Z","iopub.status.idle":"2025-04-24T14:51:25.215449Z","shell.execute_reply.started":"2025-04-24T14:51:25.207991Z","shell.execute_reply":"2025-04-24T14:51:25.214601Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Valutiamo le performance al variare della metrica\n# in questo caso le performance devono essere salvate in un dizionario. Ogni chiave sarà il nome della metrica usata, il valore corrispondente invece sarà l' accuracy ottenuta.\n\nmetrics = ['euclidean', 'manhattan', 'minkowski', 'cosine']\ntest_scores = {}\ntrain_scores = {}\n\n# Istanziamo, alleniamo e valutiamo un K-NN per ogni metrica. Utilizziamo k=5.\n\n# svolgimento...\n\n\n# Per ogni metrica, creiamo e valutiamo il modello\nfor metric in metrics:\n    knn = KNeighborsClassifier(n_neighbors=5, metric=metric)\n    knn.fit(X_train, y_train)\n    \n    # Predizioni\n    y_train_pred = knn.predict(X_train)\n    y_test_pred = knn.predict(X_test)\n    \n    # Accuracy\n    train_scores[metric] = accuracy_score(y_train, y_train_pred)\n    test_scores[metric] = accuracy_score(y_test, y_test_pred)\n\n\n\n# Visualizziamo le performance al variare della metrica\n# N.B. la funzione plot_accuracy_metric ha bisogno dei parametri metrics, train_scores, test_scores.\n\n# svolgimento...\n\ndef plot_accuracy_metric(metrics, train_scores, test_scores):\n    bar_width = 0.35\n    x = np.arange(len(metrics))\n\n    plt.figure(figsize=(12, 6))\n\n    color_train = plt.cm.RdYlBu(0.9)\n    color_test = plt.cm.RdYlBu(0.4)\n\n    bars_train = plt.bar(x - bar_width/2, train_scores.values(), width=bar_width, label='Training', color=color_train)\n    bars_test = plt.bar(x + bar_width/2, test_scores.values(), width=bar_width, label='Testing', color=color_test)\n\n    plt.xticks(ticks=x, labels=metrics)\n    plt.xlabel('Metriche')\n    plt.ylabel('Accuratezza')\n    plt.title('KNN: Accuratezza vs. Metriche')\n    plt.legend(loc='lower right')\n    plt.grid(axis='y')\n\n    for bar in bars_train:\n        yval = bar.get_height()\n        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n\n    for bar in bars_test:\n        yval = bar.get_height()\n        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:51:29.190438Z","iopub.execute_input":"2025-04-24T14:51:29.190792Z","iopub.status.idle":"2025-04-24T14:51:29.311653Z","shell.execute_reply.started":"2025-04-24T14:51:29.190767Z","shell.execute_reply":"2025-04-24T14:51:29.310860Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Esercizio 2: Implementare Decision Trees**\n\nPer implementare il classificatore Decision Tree, utilizzeremo la classe `sklearn.tree.DecisionTreeClassifier` presente in `scikit-learn`. La documentazione è disponibile [a questo link](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n\nDi seguito vediamo i parametri chiave che bisogna specificare al momento della creazione dell'istanza:\n\n* **`criterion`**: Funzione da utilizzare per misurare la qualità di uno split. \n\n* **`max_depth`**: Profondità massima dell'albero. Limitare la profondità aiuta a prevenire l'overfitting.\n\n* **`min_samples_split`**: Numero minimo di campioni richiesti per dividere un nodo. Valori più alti rendono l'albero più conservativo.\n\n* **`min_samples_leaf`**: Numero minimo di campioni che devono essere presenti in un nodo foglia. Prevenire nodi foglia con pochi campioni può migliorare la generalizzazione.\n\n\n### Esempio di sintassi per istanziare, addestrare e predire\n\n```python\n# Importo DecisionTreeClassifier da scikit-learn\nfrom sklearn.tree import DecisionTreeClassifier\n\n# 1. Instanzio il modello Decision Tree\n# Durante la creazione dell'istanza imposto i parametri che desidero\nmodel = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=10)\n\n# 2. Train del modello utilizzando il metodo .fit()\nmodel.fit(X_train, y_train)\n\n# 3. Calcolo delle predizioni utilizzando il metodo .predict()\npredictions = model.predict(X_test)\n","metadata":{}},{"cell_type":"markdown","source":"## **Esercizio 3: Istanziare allenare e valutare un modello DecisionTree**\n\nIn linea con quanto visto finora, istanziamo, alleniamo e valutiamo un modello di DecisionTree. Utilizziamo:\n\n* `criterion`=`'entropy'`\n\n* `random_state` = 42 \n\nIl valore di `random_state` non ha un significato particolare, ma ci permette di rendere l' esperimento deterministico. \n\nI passaggi per questo esercizio sono uguali a quanto visto in precedenza per K-NN.","metadata":{}},{"cell_type":"code","source":"# Importiamo DecisionTree \nfrom sklearn.tree import DecisionTreeClassifier, plot_tree","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1 - Creiamo un albero decisionale\n\n# svolgimento...\n\n\n# Step 2 - Alleniamo il modello\n\n# svolgimento...\n\n\n# Step 3 - Calcoliamo le predizioni\n\n# svolgimento...\n\n\n# Step 4 - Valutiamo il modello, calcoliamo accuracy e confusion matrix\n\n# svolgimento...","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualizzazione dell'albero creato\n# dovete sostituire alla funzione plot_tree il primo parametro. Nello specifico dovete sostituirlo con il nome che avete dato al vostro DecisionTree.\n\nplt.figure(figsize=(20, 10))\nplot_tree(dt_classifier, feature_names=feature_names, class_names=target_names, \n          filled=True, rounded=True, fontsize=12)\nplt.title('Decision Tree')\nplt.show()\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Esercizio 4: Valutiamo le performance di un DecisionTree al variare di alcuni parametri**\n\nCome abbiamo fatto per K-NN, vogliamo valutare come variano le performance di un Decision Tree al variare di alcuni parametri. Nello specifico vogliamo valutare il modello al variare di:\n\n* **`max_depth`**: Profondità massima dell'albero. \n","metadata":{}},{"cell_type":"code","source":"# Funzione per plottare l' accuracy al variare della max_depth del modello\n\ndef plot_accuracy_depth(k_values, train_scores, test_scores):\n    plt.figure(figsize=(12, 6))\n    \n    plt.plot(k_values, train_scores, 'o-', label='Accuratezza Training')\n    plt.plot(k_values, test_scores, 'o-', label='Accuratezza Testing')\n    \n    plt.xlabel('Profondità massima dell\\'albero')\n    plt.ylabel('Accuratezza')\n    plt.title('Decision Tree: Accuratezza vs. Depth')\n    plt.legend()\n    plt.grid(True)\n    plt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Confrontiamo alberi con diverse profondità massime\n\nmax_depths = [2, 3, 4, 5]\ntrain_accuracy = []\ntest_accuracy = []\n\n# Istanziamo, alleniamo e valutiamo un DecisionTree per ogni valore di max_depth\n\n# svoglimento...\n\n\n# Visualizziamo l'effetto della profondità sull'accuratezza\n\n# svolgimento...","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Esercizio 5: Ottimizzazione Decision Tree con GridSearch e Cross Validation**\n\nPossiamo ottimizzare le performance di un Decision Tree specificando ulteriori parametri. Lo scopo di questo esercizio è trovare la miglior combinazione di parametri che massimizza l' accuracy del nostro modello. Per trovare questa configurazione utilizzeremo la funzione `GridSearchCV` che effettua Grid Search e Cross Validation contemporaneamente.\n\nInnanzitutto proviamo a istanziare un Decision Tree specificando più parametri. Nello specifico impostiamo:\n\n* `max_depth` = `3`\n\n* `min_samples_split` = `5`\n\n* `min_samples_leaf` = `2`\n\nVediamo se l' aggiunta di questi parametri incrementa le performance ottenute precedentemente.\n\nOvviamente i parametri impostati precedentemente devono essere mantenuti.","metadata":{}},{"cell_type":"code","source":"# Albero ottimizzato con parametri più controllati\n\n# Istanziamo il nuovo albero specificando tutti i parametri di cui abbiamo bisogno.\n\n# svolgimento...\n\n\n# Alleniamo l' albero\n\n# svolgimento...\n\n\n# Effettuare le predizioni del nuovo albero allenato\n\n# svolgimento...\n\n\n# Rappresentiamo il nuovo albero\n# Dovete sostituire il primo parametro della funzione plot_tree con il nome del vostro albero.\n\nplt.figure(figsize=(15, 8))\nplot_tree(dt_2nd, feature_names=feature_names, class_names=target_names, \n          filled=True, rounded=True, fontsize=10)\nplt.title('Albero Decisionale')\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Importanza delle features**\n\nPossiamo estrarre dal nostro modello Decision Tree l' importanza delle singole feature, cioè quanto una feature aiuda a ridurre il criterio scelto, l' entropia nel nostro caso. \n\nQuesta informazione è contenuta in `.feature_importances_`. \n\nUna volta estratti questi valori, ordiniamoli in ordine decrescente e utilizziamo la funzione `plot_top_feature_importance` definita nella cella seguente per rappresentarne il grafico. La funzione richiede due parametri:\n\n* **Vettore importanze:** il vettore contenente l' importanza delle features ottenuto dall' estrazione.\n\n* **Nomi delle features:** i nomi delle feature che abbiamo estratto all' inizio dell' esercitazione quando abbiamo importato il dataset.","metadata":{}},{"cell_type":"code","source":"def plot_top_feature_importance(importances, feature_names):\n    # Ordina le importanze e ottieni i primi `top_n` indici\n    top_n=10\n    indices = np.argsort(importances)[::-1][:top_n]\n\n    plt.figure(figsize=(10, 6))\n    plt.title('Importanza delle Feature')\n    \n    # Plotta solo le prime `top_n` barre\n    plt.bar(range(top_n), importances[indices], align='center', color='skyblue')\n    \n    plt.xticks(range(top_n), [feature_names[i] for i in indices], rotation=45)\n    plt.xlabel('Feature')\n    plt.ylabel('Importanza')\n    plt.tight_layout()  # Aggiunge spazio tra i lati del grafico\n    plt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Estrai l' importanza delle features da .feature_importances_\n\n# svolgimento...\n\n\n# Riordina in ordine decrescente\n\n# svolgimento...\n\n\n# Rappresentiamo il grafico\n\n# svolgimento...","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Grid search**\n\nPoichè i parametri impostabili in un modello sono numerosi testare le singole configurazioni è dispendioso. Tuttavia la ricerca dei parametri ottimali è l' unico modo che abbiamo per assicurarci di estrarre la miglior performance dal nostro modello. In questi casi ci sono diverse strateggie per cercare la configurazione migliore. Una di questa è la **Grid search** (letteralmente **ricerca a griglia**) che consiste nel testare tutte le possibili configurazioni e selezionare la migliore. Chiaramente testare tutte le configurazioni rende il grid search un algoritmo molto dispendioso dal punto di vista computazionale.\n\nPossiamo implementare un algoritmo di grid search utilizzando la classe `GridSearchCV` di `sklearn` che effettua contemporaneamente ricerca a griglia e cross-validation. \n\n#### Guida per Grid Search:\n\nI seguenti passaggi devono guidarvi all' utilizzo di `GridSearchCV` per trovare la miglior configurazione per un modello di DecisionTree per il nostro dataset.\n\n1. **Istanziamo un' oggetto `GridSearchCV`:** per creare l' oggetto `GridSearchCV` dobbiamo specificare i seguenti parametri\n\n    * Modello che vogliamo usare\n\n    * Dizionario contenente come chiavi i parametri che vogliamo testare, e come value i valori che vogliamo impiegare\n\n    * `cv` cioè il nomero di fold che vogliamo utilizzare per la cross-validaton\n\n    * `scoring` ovvero la metrica da utilizzare per valutare, ad esempio `accuracy`\n\n2. **Eseguire Grid Search:** utilizziamo il metodo `.fit()` dell' oggetto `GridSearchCV` definito al punto 1 per eseguire l' algoritmo\n\n3. **Stampare configurazione migliore:** dopo aver eseguito il `.fit()`, l' oggetto `GridSearchCV` ci permette di accedere ad alcuni attributi:\n\n    * `.best_params_`: un dizionario che rappresenta la miglior configurazione.\n\n    * `.best_scores_`: il valore migliore ottenuto come accuracy.\n\n    * `.best_estimator_`: il modello allenato con la configurazione migliore. ","metadata":{}},{"cell_type":"code","source":"# Step 1 - Istanziare l' oggetto GridSearchCV\n\nfrom sklearn.model_selection import GridSearchCV\n\n# Definizione del grid di parametri\nparam_grid = {\n    'max_depth': [3, 4, 5, 6, 7, None],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'criterion': ['entropy']\n}\n\n# svolgimento...","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2 - Eseguire Grid Search\n\n# svolgimento...","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3 - Stampare i risultati\n# Stampare la migliore configurazione e la migliore accuracy\n\n# svolgimento...","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Esercizio 6: Model Selection classificatori**\n\nAvendo affrontato tutti i classificatori visti in questo corso, possiamo adesso procedere alla fase di **model selection**. Vogliamo trovare quale classificatore la relativa configurazione che meglio performano su uno specifico dataset. \n\n### **Dataset**\n\nPer questo esercizio utilizzeremo il dataset `Vehicle Silhouette` che trovato al seguente [link](https://archive.ics.uci.edu/dataset/149/statlog+vehicle+silhouettes). Il dataset contiene 846 campioni su 18 features, e contiene informazioni circa le dimensioni di alcuni veicoli. L' obiettivo è classificare ogni campione in 4 possibili classi. ","metadata":{}},{"cell_type":"code","source":"!pip install ucimlrepo","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ucimlrepo import fetch_ucirepo \n  \n# fetch dataset \nstatlog_vehicle_silhouettes = fetch_ucirepo(id=149) \n  \n# data (as pandas dataframes) \nX = statlog_vehicle_silhouettes.data.features \ny = statlog_vehicle_silhouettes.data.targets ","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# svolgimento...","metadata":{},"outputs":[],"execution_count":null}]}